AWSTemplateFormatVersion: '2010-09-09'
Description: "(0008) Deploy SAP HANA on AWS"
Parameters:
  VPCID:
    Description: The existing Amazon VPC where you want to deploy SAP HANA.
    Type: AWS::EC2::VPC::Id
    ConstraintDescription: This must be a your VPC CIDR
  PrivSubCIDR:
    Description: CIDR block of the private subnet where SAP HANA will be deployed.
    Type: String
    Default: 10.254.89.0/24
    AllowedPattern: "^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/([0-9]|[1-2][0-9]|3[0-2]))$"
  DMZCIDR:
    Description: CIDR block of the public DMZ subnet where BASTION Host / NAT Gateway exist.
    Type: String
    Default: 10.0.2.0/24
    AllowedPattern: "^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/([0-9]|[1-2][0-9]|3[0-2]))$"
  RemoteAccessCIDR:
    Description: CIDR block from where you want to access your RDP instance.
    Type: String
    Default: 0.0.0.0/0
    AllowedPattern: "^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/([0-9]|[1-2][0-9]|3[0-2]))$"
    ConstraintDescription: This must be a valid CIDR range in the format x.x.x.x/x.
  HANASubnet:
    Type: AWS::EC2::Subnet::Id
    Description: The existing private subnet in your VPC where you want to deploy SAP HANA.
  ApplicationCIDR:
    Description: CIDR block of subnet where SAP Application servers are deployed.
    Type: String
    AllowedPattern: "^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/([0-9]|[1-2][0-9]|3[0-2]))$"
    Default: 10.254.89.0/24
    ConstraintDescription: This must be a valid CIDR range in the format.
  DMZSubnet:
    Type: AWS::EC2::Subnet::Id
    Description: The existing public subnet in your VPC where you want to deploy the
      optional RDP instance.
  DomainName:
    Type: String
    Description: Name to use for fully qualified domain names.
    Default: production.eu1.sap.klarna.net
  HANAMasterHostname:
    Type: String
    Description: Host name to use for SAP HANA master node (DNS short name).
    Default: saps4-p-d1
  HANAWorkerHostname:
    Type: String
    Description: Host name to use for SAP HANA worker node(s) (DNS short name).
    Default: saps4-p-d1
  PrivateBucket:
    Description: Main build bucket where templates and scripts are located.
    Type: String
    Default: fineng
  CustomStorageConfig:
    Description: S3 location where custom storage configuration file is localted.
    Type: String
    Default: aws-quickstart/quickstart-sap-hana/scripts
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Default: home
    Description: Name of an existing Amazon EC2 key pair. All instances will launch
      with this key pair.
  HANAInstallMedia:
    Description: Full path to Amazon S3 location of SAP HANA software files (s3://myhanabucket/sap-hana2-sps02/).
    Type: String
    Default: ''
  EnableLogging:
    Description: Enable (Yes) or disable (No) logging with AWS CloudTrail and AWS
      Config.
    Default: 'No'
    Type: String
    AllowedValues:
    - 'Yes'
    - 'No'
  CloudTrailS3Bucket:
    Description: Name of S3 bucket where AWS CloudTrail trails and AWS Config log
      files can be stored (e.g., mycloudtrail).
    Default: ''
    Type: String
  AutoRecovery:
    Type: String
    Description: Enable (Yes) or disable (No) automatic recovery feature for SAP HANA
      nodes.
    Default: 'Yes'
    AllowedValues:
    - 'Yes'
    - 'No'
  Encryption:
    Type: String
    Description: Enable (Yes) or disable (No) encryption on EBS volumes.
    Default: 'No'
    AllowedValues:
    - 'Yes'
    - 'No'
  VolumeTypeHanaData:
    Type: String
    Description: 'EBS volume type for SAP HANA Data: General Purpose SSD (gp2) or
      Provisioned IOPS SSD (io1).'
    Default: gp2
    AllowedValues:
    - gp2
    - io1
  VolumeTypeHanaLog:
    Type: String
    Description: 'EBS volume type for SAP HANA Log: General Purpose SSD (gp2) or Provisioned
      IOPS SSD (io1).'
    Default: gp2
    AllowedValues:
    - gp2
    - io1
  MyOS:
    Type: String
    Description: Operating system RHEL and version for hana nodes.
    Default: RedHatLinux73ForSAP
    AllowedValues:
    - RedHatLinux73ForSAP
  InstallRDPInstance:
    Type: String
    Description: Install (Yes) or don't install (No) optional Windows RDP instance.
    Default: 'No'
    AllowedValues:
    - 'Yes'
    - 'No'
  InstallHANA:
    Type: String
    Description: Install (Yes) or don't install (No) HANA. When set to No, only AWS
      infrastructure is provisioned.
    Default: 'Yes'
    AllowedValues:
    - 'Yes'
    - 'No'
  RDPInstanceType:
    Type: String
    Description: Instance type for Windows RDP instance.
    Default: c4.large
    AllowedValues:
    - c4.large
    - c4.xlarge
    - m4.large
    - m4.xlarge
  MyInstanceType:
    Type: String
    Description: Instance type for SAP HANA host.
    Default: x1.16xlarge
    AllowedValues:
    - r3.8xlarge
    - r3.4xlarge
    - r3.2xlarge
    - r4.16xlarge
    - r4.8xlarge
    - r4.4xlarge
    - r4.2xlarge
    - x1.16xlarge
    - x1.32xlarge
    - x1e.4xlarge
    - x1e.32xlarge
  HostCount:
    Type: Number
    Description: Total number of SAP HANA nodes you want to deploy in the SAP HANA
      cluster.
    Default: '1'
    MinValue: '1'
    MaxValue: '5'
  SID:
    Type: String
    Default: HDB
    Description: SAP HANA system ID for installation and setup.
    AllowedPattern: "([A-Z]{1}[0-9A-Z]{2})"
    ConstraintDescription: This value must consist of 3 characters.
  SAPInstanceNum:
    Type: String
    Default: '00'
    Description: SAP HANA instance number to use for installation and setup, and to
      open ports for security groups.
    AllowedPattern: "([0-8]{1}[0-9]{1}|[9]{1}[0-7]{1})"
    ConstraintDescription: Instance number must be between 00 and 97.
  HANAMasterPass:
    Type: String
    Description: SAP HANA password to use during installation.
    NoEcho: 'true'
    MinLength: '8'
    AllowedPattern: "^(?=.*?[a-z])(?=.*?[A-Z])(?=.*[0-9]).*"
    ConstraintDescription: This must be at least 8 characters, including uppercase,
      lowercase, and numeric values.
  SAPTZ:
    AllowedValues:
    - SE
    - ET
    - JT
    - PT
    - UC
    ConstraintDescription: This value must consist of 2 characters.
    Default: UC
    Description: The TimeZone of your SAP HANA Server (PT, CT, ET, or UTC)
    Type: String
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: Existing network infrastructure details
      Description:
        default: ''
      Parameters:
      - VPCID
      - HANASubnet
      - DMZSubnet
      - PrivSubCIDR
      - DMZCIDR
    - Label:
        default: Server and storage configuration
      Description:
        default: ''
      Parameters:
      - MyOS
      - SLESBYOSRegCode
      - MyInstanceType
      - HostCount
      - AutoRecovery
      - KeyName
      - VolumeTypeHanaData
      - VolumeTypeHanaLog
      - Encryption
    - Label:
        default: SAP HANA database configuration
      Description:
        default: ''
      Parameters:
      - DomainName
      - HANAMasterHostname
      - HANAWorkerHostname
      - SID
      - SAPInstanceNum
      - HANAMasterPass
      - SAPTZ
      - HANAInstallMedia
      - InstallHANA
    - Label:
        default: Optional configuration
      Description:
        default: ''
      Parameters:
      - PlacementGroupName
      - InstallRDPInstance
      - RDPInstanceType
      - RemoteAccessCIDR
      - ApplicationCIDR
      - EnableLogging
      - CloudTrailS3Bucket
      - Proxy
    - Label:
        default: Advanced configuration (Do not modify unless directed by AWS Support)
      Description:
        default: ''
      Parameters:
      - PrivateBucket
      - CustomStorageConfig
    ParameterLabels:
      VPCID:
        default: Choose VPC ID
      PrivSubCIDR:
        default: Enter CIDR block for private subnet
      DMZSubnet:
        default: Choose public subnet
      DMZCIDR:
        default: Enter CIDR block for public subnet
      HANASubnet:
        default: Choose private subnet
      RemoteAccessCIDR:
        default: Enter CIDR block for RDP access
      DomainName:
        default: Enter domain name
      HANAMasterHostname:
        default: Enter SAP HANA master host name
      HANAWorkerHostname:
        default: Enter SAP HANA worker host name
      HANAInstallMedia:
        default: Enter Amazon S3 URL for SAP HANA software
      CloudTrailS3Bucket:
        default: Enter S3 bucket name to store AWS CloudTrail trails and AWS Config
          logs
      PlacementGroupName:
        default: Enter optional placement group name
      PrivateBucket:
        default: Enter private bucket
      CustomStorageConfig:
        default: Enter custom storage configuration location
      Proxy:
        default: Enter proxy server address
      KeyName:
        default: Choose key pair
      AutoRecovery:
        default: Would you like to turn on automatic recovery?
      InstallRDPInstance:
        default: Do you need a Windows RDP instance?
      InstallHANA:
        default: Install SAP HANA software?
      Encryption:
        default: Would you like to turn on encryption?
      VolumeTypeHanaData:
        default: Choose storage volume type for SAP HANA Data
      VolumeTypeHanaLog:
        default: Choose storage volume type for SAP HANA Log
      MyOS:
        default: Choose operating system for SAP HANA
      SLESBYOSRegCode:
        default: Enter SUSE BYOS Registration Code
      MyInstanceType:
        default: Choose instance type for SAP HANA
      HostCount:
        default: Enter number of SAP HANA hosts
      SID:
        default: Enter SAP HANA system ID
      SAPInstanceNum:
        default: Enter SAP HANA instance number
      HANAMasterPass:
        default: Enter SAP HANA password
      RDPInstanceType:
        default: Choose instance type for RDP host
      EnableLogging:
        default: Would you like to enable AWS CloudTrail trails and AWS Config?
      SAPTZ:
        default: Enter SAP HANA Server timezone
      ApplicationCIDR:
        default: Enter CIDR block of your SAP Application Servers
  AutoRecoveryMaster:
    Fn::Equals:
    - Ref: AutoRecovery
    - 'Yes'
  NeedWindowsInstance:
    Fn::Equals:
    - Ref: InstallRDPInstance
    - 'Yes'
  PlacementGroupNull:
    Fn::Equals:
    - Ref: PlacementGroupName
    - ''
  UseEncryption:
    Fn::Equals:
    - Ref: Encryption
    - 'Yes'
  IfLogging:
    Fn::Equals:
    - Ref: EnableLogging
    - 'Yes'
  IfAppSubnet:
    Fn::Not:
    - Fn::Equals:
      - Ref: ApplicationCIDR
      - 0.0.0.0/0
  IfUseSLES:
    Fn::Equals:
    - Fn::FindInMap:
      - SAPAMINameMap
      - Ref: MyOS
      - Code
    - SLES
Mappings:
  SAPAMINameMap:
    RedHatLinux73ForSAP:
      Code: RHEL73SAPHVM
  AWSAMIRegionMap:
    AMI:
      RHEL73SAPHVM: SAP-7.3_HVM-20180116-x86_64-1-Hourly2-GP2-b676039c-a4f8-4be7-9866-c804b1ade684-ami-d4ffddae.4
    eu-central-1:
      RHEL73SAPHVM: ami-d866f9b7
    eu-west-1:
      RHEL73SAPHVM: ami-e365fd9a
    eu-west-2:
      RHEL73SAPHVM: ami-03fee567
    eu-west-3:
      RHEL73SAPHVM: ami-7ae85e07
Outputs:
  HANAMasterInstanceIP:
    Description: HANA Master Node IP Address
    Value:
      Fn::GetAtt:
      - HANAMasterInstance
      - PrivateIp
  HANAMasterSecurityGroup:
    Description: Security Group created for the SAP HANA Master node
    Value:
      Fn::GetAtt:
      - HANASecurityGroup
      - GroupId
  HANAMasterInstanceRole:
    Description: Instance Role Name for HANA Instance
    Value:
      Ref: HANAIAMRole
  HANAMasterInstanceId:
    Description: Instance Id for HANA Instance
    Value:
      Ref: HANAMasterInstance
Resources:
  Trail:
    DependsOn:
    - BucketPolicy
    Type: AWS::CloudTrail::Trail
    Condition: IfLogging
    Properties:
      IncludeGlobalServiceEvents: 'true'
      S3BucketName:
        Ref: CloudTrailS3Bucket
      SnsTopicName:
        Ref: AWS::NoValue
      IsLogging: 'true'
  BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: IfLogging
    Properties:
      Bucket:
        Ref: CloudTrailS3Bucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: AWSCloudTrailAclCheck20150319
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: s3:GetBucketAcl
          Resource:
            Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: CloudTrailS3Bucket
        - Sid: AWSCloudTrailWrite20150319
          Effect: Allow
          Principal:
            Service: cloudtrail.amazonaws.com
          Action: s3:PutObject
          Resource:
            Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: CloudTrailS3Bucket
              - "/AWSLogs/"
              - Ref: AWS::AccountId
              - "/*"
          Condition:
            StringEquals:
              s3:x-amz-acl: bucket-owner-full-control
        - Sid: AWSConfigBucketPermissionsCheck
          Effect: Allow
          Principal:
            Service:
            - config.amazonaws.com
          Action: s3:GetBucketAcl
          Resource:
            Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: CloudTrailS3Bucket
        - Sid: " AWSConfigBucketDelivery"
          Effect: Allow
          Principal:
            Service:
            - config.amazonaws.com
          Action: s3:PutObject
          Resource:
            Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: CloudTrailS3Bucket
              - "/AWSLogs/"
              - Ref: AWS::AccountId
              - "/Config/*"
          Condition:
            StringEquals:
              s3:x-amz-acl: bucket-owner-full-control
  ConfigRecorder:
    DependsOn:
    - AWSConfigIAMRole
    Type: AWS::Config::ConfigurationRecorder
    Condition: IfLogging
    Properties:
      Name: HANAQuickStart-ConfigRecord
      RecordingGroup:
        ResourceTypes:
        - AWS::S3::Bucket
        - AWS::CloudTrail::Trail
        - AWS::EC2::Instance
        - AWS::EC2::SecurityGroup
        - AWS::EC2::NetworkInterface
        - AWS::EC2::Volume
        - AWS::EC2::VPC
        - AWS::EC2::Subnet
        - AWS::EC2::RouteTable
        - AWS::EC2::NetworkAcl
      RoleARN:
        Fn::GetAtt:
        - AWSConfigIAMRole
        - Arn
  DeliveryChannel:
    Type: AWS::Config::DeliveryChannel
    Condition: IfLogging
    Properties:
      ConfigSnapshotDeliveryProperties:
        DeliveryFrequency: One_Hour
      S3BucketName:
        Ref: CloudTrailS3Bucket
  AWSConfigIAMRole:
    Type: AWS::IAM::Role
    Condition: IfLogging
    Properties:
      Path: "/"
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSConfigRole
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - config.amazonaws.com
          Action:
          - sts:AssumeRole
  DeploymentInterruptQ:
    Type: AWS::SQS::Queue
    Properties:
      DelaySeconds: 0
      VisibilityTimeout: 0
  HANAMasterInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      Description: Network Interface for HANA Master
      SubnetId:
        Ref: HANASubnet
      GroupSet:
      - Ref: HANASecurityGroup
      SourceDestCheck: 'true'
      Tags:
      - Key: Network
        Value: Private
  HANAMasterCloneInterface:
    Type: AWS::EC2::NetworkInterface
    Properties:
      Description: Network Interface for HANA Master Clone (PreCheck)
      SubnetId:
        Ref: HANASubnet
      GroupSet:
      - Ref: HANASecurityGroup
      SourceDestCheck: 'true'
      Tags:
      - Key: Network
        Value: Private
  HANASecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Enable external access to the HANA Master and allow communication
        from slave instances
      VpcId:
        Ref: VPCID
      SecurityGroupIngress:
      - IpProtocol: tcp
        CidrIp:
          Ref: PrivSubCIDR
        FromPort: '1'
        ToPort: '65535'
      - IpProtocol: udp
        CidrIp:
          Ref: PrivSubCIDR
        FromPort: '111'
        ToPort: '111'
      - IpProtocol: udp
        CidrIp:
          Ref: PrivSubCIDR
        FromPort: '2049'
        ToPort: '2049'
      - IpProtocol: udp
        CidrIp:
          Ref: PrivSubCIDR
        FromPort: '4000'
        ToPort: '4002'
      - IpProtocol: icmp
        CidrIp:
          Ref: PrivSubCIDR
        FromPort: "-1"
        ToPort: "-1"
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '5'
            - Ref: SAPInstanceNum
            - '13'
        ToPort:
          Fn::Join:
          - ''
          - - '5'
            - Ref: SAPInstanceNum
            - '14'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '13'
        ToPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '13'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '15'
        ToPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '15'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '17'
        ToPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '17'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '41'
        ToPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - '44'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '80'
            - Ref: SAPInstanceNum
            - ''
        ToPort:
          Fn::Join:
          - ''
          - - '80'
            - Ref: SAPInstanceNum
            - ''
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - 09
        ToPort:
          Fn::Join:
          - ''
          - - '3'
            - Ref: SAPInstanceNum
            - 09
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort:
          Fn::Join:
          - ''
          - - '43'
            - Ref: SAPInstanceNum
            - ''
        ToPort:
          Fn::Join:
          - ''
          - - '43'
            - Ref: SAPInstanceNum
            - ''
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort: '8080'
        ToPort: '8080'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort: '8443'
        ToPort: '8443'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort: '1128'
        ToPort: '1128'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort: '1129'
        ToPort: '1129'
      - IpProtocol: tcp
        CidrIp:
          Ref: DMZCIDR
        FromPort: '22'
        ToPort: '22'
      SecurityGroupEgress:
      - IpProtocol: "-1"
        CidrIp: 0.0.0.0/0
        FromPort: '1'
        ToPort: '65535'
  HANASecurityGroupUpdate:
    Type: AWS::EC2::SecurityGroupIngress
    Condition: IfAppSubnet
    Properties:
      CidrIp:
        Ref: ApplicationCIDR
      Description: SAP Client Traffic
      IpProtocol: tcp
      FromPort:
        Fn::Join:
        - ''
        - - '3'
          - Ref: SAPInstanceNum
          - '13'
      ToPort:
        Fn::Join:
        - ''
        - - '3'
          - Ref: SAPInstanceNum
          - '17'
      GroupId:
        Ref: HANASecurityGroup
  HANAIAMRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - ssm.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
      Policies:
      - PolicyName: HANA-QuickStart
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:ListBucket
            - s3:GetBucketLocation
            - ec2:Describe*
            - ec2:ModifyInstanceAttribute
            - ec2:AttachVolume
            - ec2:CreateTags
            - ec2:CreateVolume
            Resource: "*"
          - Effect: Allow
            Action: cloudwatch:GetMetricStatistics
            Resource: "*"
          - Effect: Allow
            Action:
            - sqs:*
            - dynamodb:*
            - dynamodb:Scan
            - dynamodb:Query
            - dynamodb:GetItem
            - dynamodb:BatchGetItem
            - dynamodb:UpdateTable
            - cloudformation:DescribeStacks
            - cloudformation:DescribeStackEvents
            - cloudformation:DescribeStackResource
            - cloudformation:DescribeStackResources
            - cloudformation:GetTemplate
            - cloudformation:List*
            Resource:
            - "*"
  HANAIAMProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - Ref: HANAIAMRole
  WaitForHANAInstall:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: HANAMasterInstance
    Properties:
      Handle:
        Ref: WaitForMasterInstallWaitHandle
      Timeout: '7200'
  WaitForMasterInstallWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle
    Properties: {}
  RDPInstanceRootRole:
    Condition: NeedWindowsInstance
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: root
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - s3:*
            - ec2:Describe*
            - ec2:AttachNetworkInterface
            - ec2:AttachVolume
            - ec2:CreateTags
            - ec2:CreateVolume
            - ec2:DeleteVolume
            - ec2:RunInstances
            - ec2:StartInstances
            - ec2:CreateSecurityGroup
            - ec2:CreatePlacementGroup
            - ec2:CreateSnapshot
            Resource: "*"
          - Action:
            - sqs:*
            Effect: Allow
            Resource: "*"
          - Effect: Allow
            Action:
            - cloudformation:CreateStack
            - cloudformation:DeleteStack
            - cloudformation:DescribeStack
            - cloudformation:EstimateTemplateCost
            - cloudformation:ValidateTemplate
            - cloudformation:DescribeStackEvents
            - cloudformation:DescribeStackResource
            - cloudformation:DescribeStackResources
            - cloudformation:DescribeStacks
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - iam:CreateRole
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - iam:PutRolePolicy
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - iam:CreateInstanceProfile
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - iam:AddRoleToInstanceProfile
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - iam:PassRole
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - ec2:RevokeSecurityGroupEgress
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - ec2:AuthorizeSecurityGroupEgress
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - ec2:AuthorizeSecurityGroupIngress
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - ec2:CreateNetworkInterface
            Resource:
            - "*"
          - Effect: Allow
            Action:
            - ec2:ModifyNetworkInterfaceAttribute
            Resource:
            - "*"
  RDPProfile:
    Condition: NeedWindowsInstance
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - Ref: RDPInstanceRootRole
  RDPSecurityGroup:
    Condition: NeedWindowsInstance
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: RDP Instance security group
      VpcId:
        Ref: VPCID
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '3389'
        ToPort: '3389'
        CidrIp:
          Ref: RemoteAccessCIDR
      SecurityGroupEgress:
      - IpProtocol: tcp
        FromPort: '1'
        ToPort: '65535'
        CidrIp: 0.0.0.0/0
  RDPEIP:
    Condition: NeedWindowsInstance
    Type: AWS::EC2::EIP
    Properties:
      Domain: vpc
  RDPInterface:
    Condition: NeedWindowsInstance
    Type: AWS::EC2::NetworkInterface
    Properties:
      SubnetId:
        Ref: DMZSubnet
      Description: Interface for RDP Instance
      GroupSet:
      - Ref: RDPSecurityGroup
      SourceDestCheck: 'true'
      Tags:
      - Key: Network
        Value: Public
  AssociateRDPEIP:
    Condition: NeedWindowsInstance
    Type: AWS::EC2::EIPAssociation
    Properties:
      AllocationId:
        Fn::GetAtt:
        - RDPEIP
        - AllocationId
      NetworkInterfaceId:
        Ref: RDPInterface
  RDPInstance:
    Condition: NeedWindowsInstance
    Type: AWS::EC2::Instance
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: RDPInterface
        DeviceIndex: '0'
      KeyName:
        Ref: KeyName
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - WS2012R2
      IamInstanceProfile:
        Ref: RDPProfile
      Tags:
      - Key: Name
        Value: SAP RDP Instance (Public Subnet)
      InstanceType:
        Ref: RDPInstanceType
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "<powershell>\n"
            - "Set-ExecutionPolicy RemoteSigned -Force \n"
            - "Start-Process -FilePath msiexec -ArgumentList /i,  \"http://sdk-for-net.amazonwebservices.com/latest/AWSToolsAndSDKForNet.msi\",
              /passive -wait \n"
            - "</powershell>"
  HANAMasterInstance:
    Type: AWS::EC2::Instance
    Metadata:
      HostRole: Master
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAMasterInterface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Master
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -xv\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Ref: HANAMasterHostname
            - "\n"
            - 'echo '
            - Fn::Join:
              - "."
              - - Ref: HANAMasterHostname
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - "."
              - - Ref: HANAMasterHostname
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh SAPInstanceNum=
            - Ref: SAPInstanceNum
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=1
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=0
            - "\n"
            - sh /root/install/writeconfig.sh BACKUP_VOL=st1
            - "\n"
            - sh /root/install/writeconfig.sh SHARED_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - "\""
                - export WaitForMasterInstallWaitHandle=
                - "\\"
                - "\""
                - Ref: WaitForMasterInstallWaitHandle
                - "\\"
                - "\""
                - "\""
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "#sh /root/install/signal-complete.sh \n"
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAMasterHostname
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Master
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - Status=PRE_INSTALL_COMPLETE
            - "\""
            - "\n"
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - " >> /root/install.log\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/install-master.sh -s '
            - Ref: SID
            - " -i "
            - Ref: SAPInstanceNum
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - " -w "
            - Ref: HANAWorkerHostname
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "MASTER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "sh /root/install/cluster-watch-engine.sh  -r \n"
            - sh /root/install/validate-install.sh "
            - Ref: WaitForMasterInstallWaitHandle
            - "\" \n"
            - "#python /root/install/postprocess.py \n"
            - "sh /root/install/cleanup.sh \n"
            - "\n"
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  PlacementGroup:
    Type: AWS::EC2::PlacementGroup
    Properties:
      Strategy: cluster
  HANAWorkerInstance1:
    Type: AWS::EC2::Instance
    Condition: TwoOrMoreNodes
    Metadata:
      HostRole: Worker
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAWorker1Interface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Worker 1
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -v\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '01'
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '01'
                - "."
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '01'
                - "."
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=0
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=1
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAWorkerHostname
            - '01'
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Worker
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "PRE_INSTALL_COMPLETE"

'
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - "\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/wait-for-master.sh

'
            - 'sh /root/install/install-worker.sh -s '
            - Ref: SID
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "WORKER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "#python /root/install/postprocess.py \n"
            - 'sh /root/install/cleanup.sh '
            - "\n"
            - "' "
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  HANAWorkerInstance2:
    Type: AWS::EC2::Instance
    Condition: ThreeOrMoreNodes
    Metadata:
      HostRole: Worker
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAWorker2Interface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Worker 2
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -v\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '02'
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '02'
                - "."
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '02'
                - "."
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=0
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=1
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAWorkerHostname
            - '02'
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Worker
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "PRE_INSTALL_COMPLETE"

'
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - "\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/wait-for-master.sh

'
            - 'sh /root/install/install-worker.sh -s '
            - Ref: SID
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "WORKER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "#python /root/install/postprocess.py \n"
            - 'sh /root/install/cleanup.sh '
            - "\n"
            - "' "
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  HANAWorkerInstance3:
    Type: AWS::EC2::Instance
    Condition: FourOrMoreNodes
    Metadata:
      HostRole: Worker
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAWorker3Interface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Worker 3
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -v\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '03'
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '03'
                - "."
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '03'
                - "."
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=0
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=1
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAWorkerHostname
            - '03'
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Worker
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "PRE_INSTALL_COMPLETE"

'
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - "\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/wait-for-master.sh

'
            - 'sh /root/install/install-worker.sh -s '
            - Ref: SID
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "WORKER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "#python /root/install/postprocess.py \n"
            - 'sh /root/install/cleanup.sh '
            - "\n"
            - "' "
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  HANAWorkerInstance4:
    Type: AWS::EC2::Instance
    Condition: FiveOrMoreNodes
    Metadata:
      HostRole: Worker
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAWorker4Interface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Worker 4
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -v\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '04'
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '04'
                - "."
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '04'
                - "."
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=0
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=1
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAWorkerHostname
            - '04'
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Worker
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "PRE_INSTALL_COMPLETE"

'
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - "\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/wait-for-master.sh

'
            - 'sh /root/install/install-worker.sh -s '
            - Ref: SID
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "WORKER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "#python /root/install/postprocess.py \n"
            - 'sh /root/install/cleanup.sh '
            - "\n"
            - "' "
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  HANAWorkerInstance5:
    Type: AWS::EC2::Instance
    Condition: SixOrMoreNodes
    Metadata:
      HostRole: Worker
    Properties:
      NetworkInterfaces:
      - NetworkInterfaceId:
          Ref: HANAWorker5Interface
        DeviceIndex: '0'
      PlacementGroupName:
        Fn::If:
        - PlacementGroupNull
        - Ref: AWS::NoValue
        - Ref: PlacementGroupName
      KeyName:
        Ref: KeyName
      BlockDeviceMappings:
      - DeviceName: "/dev/sda1"
        Ebs:
          VolumeSize: '50'
          VolumeType: gp2
      ImageId:
        Fn::FindInMap:
        - AWSAMIRegionMap
        - Ref: AWS::Region
        - Fn::FindInMap:
          - SAPAMINameMap
          - Ref: MyOS
          - Code
      IamInstanceProfile:
        Ref: HANAIAMProfile
      Tags:
      - Key: Name
        Value: SAP HANA Worker 5
      UserData:
        Fn::Base64:
          Fn::Join:
          - ''
          - - "#!/bin/bash -v\n"
            - "exec 3>&1 1>>/root/install/misc.log 2>&1 \n"
            - 'hostname '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '05'
            - "\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '05'
                - "."
                - Ref: DomainName
            - " > /etc/HOSTNAME\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - Ref: HANAWorkerHostname
                - '05'
                - "."
                - Ref: DomainName
            - " > /etc/hostname\n"
            - export http_proxy=
            - Ref: Proxy
            - "\n"
            - export https_proxy=
            - Ref: Proxy
            - "\n"
            - export HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - export HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - export no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - export NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - 'mkdir /root/install

'
            - wget https://s3.amazonaws.com/
            - Ref: PrivateBucket
            - "/scripts/download.sh --output-document=/root/install/download.sh\n"
            - 'sh /root/install/download.sh -b '
            - Ref: PrivateBucket
            - " -c "
            - Ref: CustomStorageConfig
            - "\n"
            - 'chmod 755 /root/install/*.sh

'
            - 'chmod 755 /root/install/*.py

'
            - 'echo '
            - Fn::Join:
              - _
              - - export TABLE_NAME=HANAMonitor_
                - Ref: AWS::StackName
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export TZ_INPUT_PARAM=
                - Ref: SAPTZ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export SLESBYOSRegCode=
                - Ref: SLESBYOSRegCode
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export DeploymentInterruptQ=
                - Ref: DeploymentInterruptQ
            - " >> /root/install/config.sh\n"
            - 'echo '
            - Fn::Join:
              - ''
              - - export MyOS=
                - Fn::FindInMap:
                  - SAPAMINameMap
                  - Ref: MyOS
                  - Code
            - " >> /root/install/config.sh\n"
            - sh /root/install/writeconfig.sh MyStackId=
            - Ref: AWS::StackId
            - "\n"
            - sh /root/install/writeconfig.sh INSTALL_HANA=
            - Ref: InstallHANA
            - "\n"
            - sh /root/install/writeconfig.sh HostCount=
            - Ref: HostCount
            - "\n"
            - sh /root/install/writeconfig.sh http_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTP_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh https_proxy=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh HTTPS_PROXY=
            - Ref: Proxy
            - "\n"
            - sh /root/install/writeconfig.sh no_proxy=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh NO_PROXY=localhost,127.0.0.1,169.254.169.254
            - "\n"
            - sh /root/install/writeconfig.sh IsMasterNode=0
            - "\n"
            - sh /root/install/writeconfig.sh IsWorkerNode=1
            - "\n"
            - sh /root/install/writeconfig.sh USR_SAP_VOL=gp2
            - "\n"
            - sh /root/install/writeconfig.sh REGION=
            - Ref: AWS::Region
            - "\n"
            - 'sh /root/install/install-aws.sh

'
            - 'sh /root/install/install-prereq.sh

'
            - "sh /root/install/cluster-watch-engine.sh -c \n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - DomainName=
            - Ref: DomainName
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyHostname=
            - Ref: HANAWorkerHostname
            - '05'
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - MyRole=Worker
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -i '
            - "\""
            - HostCount=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "PRE_INSTALL_COMPLETE"

'
            - 'sh /root/install/reconcile-ips.sh '
            - Ref: HostCount
            - "\n"
            - sh /root/install/fence-cluster.sh -w "PRE_INSTALL_COMPLETE_ACK=
            - Ref: HostCount
            - "\""
            - "\n"
            - 'sh /root/install/wait-for-master.sh

'
            - 'sh /root/install/install-worker.sh -s '
            - Ref: SID
            - " -p "
            - Ref: HANAMasterPass
            - " -n "
            - Ref: HANAMasterHostname
            - " -d "
            - Ref: DomainName
            - "\n"
            - 'sh /root/install/cluster-watch-engine.sh -s "WORKER_NODE_COMPLETE"

'
            - 'sh /root/install/wait-for-workers.sh '
            - Ref: HostCount
            - "\n"
            - "#python /root/install/postprocess.py \n"
            - 'sh /root/install/cleanup.sh '
            - "\n"
            - "' "
            - "\n"
      InstanceType:
        Ref: MyInstanceType
  AutoRecoverAlarmMaster:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryMaster
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minute.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAMasterInstance
  AutoRecoverAlarmWorker1:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryWorker1
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAWorkerInstance1
  AutoRecoverAlarmWorker2:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryWorker2
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAWorkerInstance2
  AutoRecoverAlarmWorker3:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryWorker3
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAWorkerInstance3
  AutoRecoverAlarmWorker4:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryWorker4
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAWorkerInstance4
  AutoRecoverAlarmWorker5:
    Type: AWS::CloudWatch::Alarm
    Condition: AutoRecoveryWorker5
    Properties:
      AlarmDescription: Trigger a recovery when instance status check fails for 5
        consecutive minutes.
      Namespace: AWS/EC2
      MetricName: StatusCheckFailed_System
      Statistic: Minimum
      Period: '60'
      EvaluationPeriods: '5'
      ComparisonOperator: GreaterThanThreshold
      Threshold: '0'
      AlarmActions:
      - Fn::Join:
        - ''
        - - 'arn:aws:automate:'
          - Ref: AWS::Region
          - ":ec2:recover"
      Dimensions:
      - Name: InstanceId
        Value:
          Ref: HANAWorkerInstance5
